{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from plotly.graph_objs import Scatter, Layout\n",
    "from plotly.offline import plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(df, sequence_length=10, split=0.8):\n",
    "    data_all = np.array(df).astype(float)    # 轉為浮點型別矩陣\n",
    "    #print(data_all.shape) # (241,1)\n",
    "    scaler = MinMaxScaler()\n",
    "    data_all = scaler.fit_transform(data_all)  # 將數據縮放為 0~1 之間\n",
    "    data = []\n",
    "    # data 資料共有 (241-10-1)=230 筆\n",
    "    for i in range(len(data_all) - sequence_length - 1):\n",
    "        # 每筆 data 資料有 11 欄\n",
    "        data.append(data_all[i: i + sequence_length + 1])\n",
    "    reshaped_data = np.array(data).astype('float64')\n",
    "\n",
    "    x = reshaped_data[:, :-1] # 第 1至第10個欄位為 特徵\n",
    "    y = reshaped_data[:, -1]  # 第 11個欄位為 label\n",
    "    #print(x.shape,y.shape) # (230,10,1) (230,1)\n",
    "    split_boundary = int(reshaped_data.shape[0] * split)\n",
    "    train_x = x[: split_boundary] # 前 80% 為 train 的特徵\n",
    "    test_x = x[split_boundary:]   # 最後 20% 為 test 的特徵\n",
    " \n",
    "    train_y = y[: split_boundary] # 前 80% 為 train 的 label\n",
    "    test_y = y[split_boundary:]   # 最後 20% 為 test 的 label\n",
    "\n",
    "    return train_x, train_y, test_x, test_y, scaler\n",
    "\n",
    "def build_model():\n",
    "    model = Sequential()     \n",
    "    # 隱藏層：256 個神經元，input_shape：(10,1)\n",
    "    # TIME_STEPS=10,INPUT_SIZE=1\n",
    "    model.add(LSTM(input_shape=(10,1),units=256,unroll=False))\n",
    "    model.add(Dense(units=1)) # 輸出層：1 個神經元\n",
    "    #compile:loss, optimizer, metrics\n",
    "    model.compile(loss=\"mse\", optimizer=\"adam\", metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def train_model(train_x, train_y, test_x, test_y):\n",
    "    model = build_model()\n",
    "    try:\n",
    "        model.fit(train_x, train_y, batch_size=10000, epochs=300, validation_split=0.1)\n",
    "        predict = model.predict(test_x)\n",
    "        predict = np.reshape(predict, (predict.size, )) #轉換為1維矩陣\n",
    "    except KeyboardInterrupt:\n",
    "        print(predict)\n",
    "        print(test_y)\n",
    "    return predict, test_y #傳回 預測值和真實值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None  #取消顯示pandas資料重設警告\n",
    "filename = './data/Train_Y.csv'\n",
    "df = pd.read_csv(filename,encoding='cp950')  #以pandas讀取檔案\n",
    "ddprice=pd.DataFrame(df['Target_Y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 162 samples, validate on 18 samples\n",
      "Epoch 1/300\n",
      "162/162 [==============================] - 1s 8ms/step - loss: 0.3575 - accuracy: 0.0000e+00 - val_loss: 0.1046 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "162/162 [==============================] - 0s 994us/step - loss: 0.2519 - accuracy: 0.0000e+00 - val_loss: 0.0551 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/300\n",
      "162/162 [==============================] - 0s 963us/step - loss: 0.1506 - accuracy: 0.0000e+00 - val_loss: 0.0210 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/300\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0674 - accuracy: 0.0062 - val_loss: 0.0119 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/300\n",
      "162/162 [==============================] - 0s 840us/step - loss: 0.0148 - accuracy: 0.0062 - val_loss: 0.0421 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/300\n",
      "162/162 [==============================] - 0s 907us/step - loss: 0.0128 - accuracy: 0.0062 - val_loss: 0.0954 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/300\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0539 - accuracy: 0.0062 - val_loss: 0.1035 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/300\n",
      "162/162 [==============================] - 0s 827us/step - loss: 0.0617 - accuracy: 0.0062 - val_loss: 0.0767 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/300\n",
      "162/162 [==============================] - 0s 901us/step - loss: 0.0387 - accuracy: 0.0062 - val_loss: 0.0458 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/300\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0159 - accuracy: 0.0062 - val_loss: 0.0249 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/300\n",
      "162/162 [==============================] - 0s 889us/step - loss: 0.0059 - accuracy: 0.0062 - val_loss: 0.0146 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/300\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0069 - accuracy: 0.0062 - val_loss: 0.0110 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/300\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.0130 - accuracy: 0.0062 - val_loss: 0.0106 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/300\n",
      "162/162 [==============================] - 0s 827us/step - loss: 0.0195 - accuracy: 0.0062 - val_loss: 0.0109 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/300\n",
      "162/162 [==============================] - 0s 907us/step - loss: 0.0238 - accuracy: 0.0062 - val_loss: 0.0111 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/300\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.0251 - accuracy: 0.0062 - val_loss: 0.0109 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/300\n",
      "162/162 [==============================] - 0s 938us/step - loss: 0.0236 - accuracy: 0.0062 - val_loss: 0.0105 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/300\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0199 - accuracy: 0.0062 - val_loss: 0.0105 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/300\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0152 - accuracy: 0.0062 - val_loss: 0.0115 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/300\n",
      "162/162 [==============================] - 0s 870us/step - loss: 0.0105 - accuracy: 0.0062 - val_loss: 0.0140 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/300\n",
      "162/162 [==============================] - 0s 858us/step - loss: 0.0068 - accuracy: 0.0062 - val_loss: 0.0184 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/300\n",
      "162/162 [==============================] - 0s 914us/step - loss: 0.0050 - accuracy: 0.0062 - val_loss: 0.0243 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/300\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.0055 - accuracy: 0.0062 - val_loss: 0.0307 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/300\n",
      "162/162 [==============================] - 0s 790us/step - loss: 0.0076 - accuracy: 0.0062 - val_loss: 0.0359 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/300\n",
      "162/162 [==============================] - 0s 901us/step - loss: 0.0100 - accuracy: 0.0062 - val_loss: 0.0382 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/300\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.0112 - accuracy: 0.0062 - val_loss: 0.0373 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/300\n",
      "162/162 [==============================] - 0s 833us/step - loss: 0.0107 - accuracy: 0.0062 - val_loss: 0.0337 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/300\n",
      "162/162 [==============================] - 0s 901us/step - loss: 0.0089 - accuracy: 0.0062 - val_loss: 0.0288 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/300\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0069 - accuracy: 0.0062 - val_loss: 0.0240 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/300\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.0054 - accuracy: 0.0062 - val_loss: 0.0200 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/300\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0048 - accuracy: 0.0062 - val_loss: 0.0170 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/300\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0062 - val_loss: 0.0150 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/300\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0058 - accuracy: 0.0062 - val_loss: 0.0138 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/300\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.0065 - accuracy: 0.0062 - val_loss: 0.0132 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/300\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0070 - accuracy: 0.0062 - val_loss: 0.0131 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/300\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.0071 - accuracy: 0.0062 - val_loss: 0.0134 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/300\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0068 - accuracy: 0.0062 - val_loss: 0.0140 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/300\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0062 - accuracy: 0.0062 - val_loss: 0.0151 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/300\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.0056 - accuracy: 0.0062 - val_loss: 0.0166 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/300\n",
      "162/162 [==============================] - 0s 988us/step - loss: 0.0050 - accuracy: 0.0062 - val_loss: 0.0185 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/300\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.0048 - accuracy: 0.0062 - val_loss: 0.0205 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/300\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0048 - accuracy: 0.0062 - val_loss: 0.0223 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/300\n",
      "162/162 [==============================] - 0s 957us/step - loss: 0.0050 - accuracy: 0.0062 - val_loss: 0.0238 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/300\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.0053 - accuracy: 0.0062 - val_loss: 0.0245 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/300\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0055 - accuracy: 0.0062 - val_loss: 0.0245 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/300\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.0055 - accuracy: 0.0062 - val_loss: 0.0237 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/300\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0053 - accuracy: 0.0062 - val_loss: 0.0225 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/300\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 0.0062 - val_loss: 0.0209 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/300\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.0048 - accuracy: 0.0062 - val_loss: 0.0194 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/300\n",
      "162/162 [==============================] - 0s 982us/step - loss: 0.0047 - accuracy: 0.0062 - val_loss: 0.0181 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/300\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0047 - accuracy: 0.0062 - val_loss: 0.0170 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/300\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0048 - accuracy: 0.0062 - val_loss: 0.0163 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/300\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.0049 - accuracy: 0.0062 - val_loss: 0.0159 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/300\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0049 - accuracy: 0.0062 - val_loss: 0.0159 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/300\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0049 - accuracy: 0.0062 - val_loss: 0.0161 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/300\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.0049 - accuracy: 0.0062 - val_loss: 0.0165 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/300\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0048 - accuracy: 0.0062 - val_loss: 0.0171 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/300\n",
      "162/162 [==============================] - 0s 957us/step - loss: 0.0047 - accuracy: 0.0062 - val_loss: 0.0179 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/300\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0046 - accuracy: 0.0062 - val_loss: 0.0187 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/300\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0046 - accuracy: 0.0062 - val_loss: 0.0194 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/300\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0046 - accuracy: 0.0062 - val_loss: 0.0199 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/300\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0046 - accuracy: 0.0062 - val_loss: 0.0201 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/300\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0047 - accuracy: 0.0062 - val_loss: 0.0201 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/300\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0047 - accuracy: 0.0062 - val_loss: 0.0198 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/300\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0046 - accuracy: 0.0062 - val_loss: 0.0193 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/300\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0046 - accuracy: 0.0062 - val_loss: 0.0187 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/300\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.0045 - accuracy: 0.0062 - val_loss: 0.0180 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/300\n",
      "162/162 [==============================] - 0s 920us/step - loss: 0.0045 - accuracy: 0.0062 - val_loss: 0.0175 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/300\n",
      "162/162 [==============================] - 0s 944us/step - loss: 0.0045 - accuracy: 0.0062 - val_loss: 0.0170 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/300\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0045 - accuracy: 0.0062 - val_loss: 0.0167 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/300\n",
      "162/162 [==============================] - 0s 827us/step - loss: 0.0045 - accuracy: 0.0062 - val_loss: 0.0166 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/300\n",
      "162/162 [==============================] - 0s 920us/step - loss: 0.0045 - accuracy: 0.0062 - val_loss: 0.0167 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/300\n",
      "162/162 [==============================] - 0s 852us/step - loss: 0.0045 - accuracy: 0.0062 - val_loss: 0.0168 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/300\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.0045 - accuracy: 0.0062 - val_loss: 0.0171 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/300\n",
      "162/162 [==============================] - 0s 858us/step - loss: 0.0044 - accuracy: 0.0062 - val_loss: 0.0174 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/300\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0044 - accuracy: 0.0062 - val_loss: 0.0177 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/300\n",
      "162/162 [==============================] - 0s 846us/step - loss: 0.0044 - accuracy: 0.0062 - val_loss: 0.0180 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/300\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0044 - accuracy: 0.0062 - val_loss: 0.0182 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/300\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0044 - accuracy: 0.0062 - val_loss: 0.0182 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/300\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 0.0062 - val_loss: 0.0181 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/300\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.0044 - accuracy: 0.0062 - val_loss: 0.0179 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/300\n",
      "162/162 [==============================] - 0s 938us/step - loss: 0.0044 - accuracy: 0.0062 - val_loss: 0.0177 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/300\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0044 - accuracy: 0.0062 - val_loss: 0.0174 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/300\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0044 - accuracy: 0.0062 - val_loss: 0.0171 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/300\n",
      "162/162 [==============================] - 0s 870us/step - loss: 0.0044 - accuracy: 0.0062 - val_loss: 0.0169 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/300\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 0.0062 - val_loss: 0.0167 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/300\n",
      "162/162 [==============================] - 0s 914us/step - loss: 0.0044 - accuracy: 0.0062 - val_loss: 0.0166 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/300\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0044 - accuracy: 0.0062 - val_loss: 0.0166 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/300\n",
      "162/162 [==============================] - 0s 901us/step - loss: 0.0043 - accuracy: 0.0062 - val_loss: 0.0167 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/300\n",
      "162/162 [==============================] - 0s 926us/step - loss: 0.0043 - accuracy: 0.0062 - val_loss: 0.0168 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/300\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.0043 - accuracy: 0.0062 - val_loss: 0.0169 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/300\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.0043 - accuracy: 0.0062 - val_loss: 0.0170 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/300\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.0043 - accuracy: 0.0062 - val_loss: 0.0171 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/300\n",
      "162/162 [==============================] - 0s 957us/step - loss: 0.0043 - accuracy: 0.0062 - val_loss: 0.0172 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/300\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 0.0043 - accuracy: 0.0062 - val_loss: 0.0172 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/300\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.0043 - accuracy: 0.0062 - val_loss: 0.0171 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/300\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.0043 - accuracy: 0.0062 - val_loss: 0.0170 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/300\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0043 - accuracy: 0.0062 - val_loss: 0.0168 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/300\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0043 - accuracy: 0.0062 - val_loss: 0.0167 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/300\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.0043 - accuracy: 0.0062 - val_loss: 0.0165 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/300\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.0043 - accuracy: 0.0062 - val_loss: 0.0164 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/300\n",
      "162/162 [==============================] - 0s 944us/step - loss: 0.0043 - accuracy: 0.0062 - val_loss: 0.0164 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/300\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0042 - accuracy: 0.0062 - val_loss: 0.0164 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/300\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0042 - accuracy: 0.0062 - val_loss: 0.0164 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/300\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0042 - accuracy: 0.0062 - val_loss: 0.0164 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/300\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 0.0042 - accuracy: 0.0062 - val_loss: 0.0165 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/300\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0042 - accuracy: 0.0062 - val_loss: 0.0165 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/300\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0042 - accuracy: 0.0062 - val_loss: 0.0165 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/300\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0042 - accuracy: 0.0062 - val_loss: 0.0165 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/300\n",
      "162/162 [==============================] - 0s 988us/step - loss: 0.0042 - accuracy: 0.0062 - val_loss: 0.0165 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0042 - accuracy: 0.0062 - val_loss: 0.0165 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/300\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 0.0062 - val_loss: 0.0164 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/300\n",
      "162/162 [==============================] - 0s 944us/step - loss: 0.0042 - accuracy: 0.0062 - val_loss: 0.0163 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/300\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0042 - accuracy: 0.0062 - val_loss: 0.0162 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/300\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0042 - accuracy: 0.0062 - val_loss: 0.0162 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/300\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0042 - accuracy: 0.0062 - val_loss: 0.0161 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/300\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 0.0062 - val_loss: 0.0161 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/300\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0041 - accuracy: 0.0062 - val_loss: 0.0161 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/300\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0041 - accuracy: 0.0062 - val_loss: 0.0161 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/300\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0041 - accuracy: 0.0062 - val_loss: 0.0161 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/300\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0041 - accuracy: 0.0062 - val_loss: 0.0161 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/300\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0041 - accuracy: 0.0062 - val_loss: 0.0161 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/300\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.0041 - accuracy: 0.0062 - val_loss: 0.0161 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/300\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0041 - accuracy: 0.0062 - val_loss: 0.0161 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/300\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0041 - accuracy: 0.0062 - val_loss: 0.0160 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/300\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0041 - accuracy: 0.0062 - val_loss: 0.0160 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/300\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0041 - accuracy: 0.0062 - val_loss: 0.0159 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/300\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.0041 - accuracy: 0.0062 - val_loss: 0.0159 - val_accuracy: 0.0000e+00\n",
      "Epoch 129/300\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0041 - accuracy: 0.0062 - val_loss: 0.0158 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/300\n",
      "162/162 [==============================] - 0s 932us/step - loss: 0.0041 - accuracy: 0.0062 - val_loss: 0.0158 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/300\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0041 - accuracy: 0.0062 - val_loss: 0.0158 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/300\n",
      "162/162 [==============================] - 0s 883us/step - loss: 0.0040 - accuracy: 0.0062 - val_loss: 0.0158 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/300\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0040 - accuracy: 0.0062 - val_loss: 0.0157 - val_accuracy: 0.0000e+00\n",
      "Epoch 134/300\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 0.0062 - val_loss: 0.0157 - val_accuracy: 0.0000e+00\n",
      "Epoch 135/300\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0040 - accuracy: 0.0062 - val_loss: 0.0157 - val_accuracy: 0.0000e+00\n",
      "Epoch 136/300\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0040 - accuracy: 0.0062 - val_loss: 0.0157 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/300\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0040 - accuracy: 0.0062 - val_loss: 0.0157 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/300\n",
      "162/162 [==============================] - 0s 975us/step - loss: 0.0040 - accuracy: 0.0062 - val_loss: 0.0157 - val_accuracy: 0.0000e+00\n",
      "Epoch 139/300\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 0.0062 - val_loss: 0.0157 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/300\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0040 - accuracy: 0.0062 - val_loss: 0.0156 - val_accuracy: 0.0000e+00\n",
      "Epoch 141/300\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0040 - accuracy: 0.0062 - val_loss: 0.0156 - val_accuracy: 0.0000e+00\n",
      "Epoch 142/300\n",
      "162/162 [==============================] - 0s 969us/step - loss: 0.0040 - accuracy: 0.0062 - val_loss: 0.0155 - val_accuracy: 0.0000e+00\n",
      "Epoch 143/300\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0040 - accuracy: 0.0062 - val_loss: 0.0155 - val_accuracy: 0.0000e+00\n",
      "Epoch 144/300\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 0.0062 - val_loss: 0.0155 - val_accuracy: 0.0000e+00\n",
      "Epoch 145/300\n",
      "162/162 [==============================] - 0s 944us/step - loss: 0.0040 - accuracy: 0.0062 - val_loss: 0.0155 - val_accuracy: 0.0000e+00\n",
      "Epoch 146/300\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0039 - accuracy: 0.0062 - val_loss: 0.0154 - val_accuracy: 0.0000e+00\n",
      "Epoch 147/300\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0039 - accuracy: 0.0062 - val_loss: 0.0154 - val_accuracy: 0.0000e+00\n",
      "Epoch 148/300\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0039 - accuracy: 0.0062 - val_loss: 0.0154 - val_accuracy: 0.0000e+00\n",
      "Epoch 149/300\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.0039 - accuracy: 0.0062 - val_loss: 0.0154 - val_accuracy: 0.0000e+00\n",
      "Epoch 150/300\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0039 - accuracy: 0.0062 - val_loss: 0.0154 - val_accuracy: 0.0000e+00\n",
      "Epoch 151/300\n",
      "162/162 [==============================] - 0s 920us/step - loss: 0.0039 - accuracy: 0.0062 - val_loss: 0.0154 - val_accuracy: 0.0000e+00\n",
      "Epoch 152/300\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0039 - accuracy: 0.0062 - val_loss: 0.0153 - val_accuracy: 0.0000e+00\n",
      "Epoch 153/300\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0039 - accuracy: 0.0062 - val_loss: 0.0153 - val_accuracy: 0.0000e+00\n",
      "Epoch 154/300\n",
      "162/162 [==============================] - 0s 833us/step - loss: 0.0039 - accuracy: 0.0062 - val_loss: 0.0153 - val_accuracy: 0.0000e+00\n",
      "Epoch 155/300\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 0.0039 - accuracy: 0.0062 - val_loss: 0.0152 - val_accuracy: 0.0000e+00\n",
      "Epoch 156/300\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0039 - accuracy: 0.0062 - val_loss: 0.0152 - val_accuracy: 0.0000e+00\n",
      "Epoch 157/300\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0039 - accuracy: 0.0062 - val_loss: 0.0152 - val_accuracy: 0.0000e+00\n",
      "Epoch 158/300\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0039 - accuracy: 0.0062 - val_loss: 0.0152 - val_accuracy: 0.0000e+00\n",
      "Epoch 159/300\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 0.0039 - accuracy: 0.0062 - val_loss: 0.0151 - val_accuracy: 0.0000e+00\n",
      "Epoch 160/300\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0038 - accuracy: 0.0062 - val_loss: 0.0151 - val_accuracy: 0.0000e+00\n",
      "Epoch 161/300\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.0038 - accuracy: 0.0062 - val_loss: 0.0151 - val_accuracy: 0.0000e+00\n",
      "Epoch 162/300\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 0.0038 - accuracy: 0.0062 - val_loss: 0.0151 - val_accuracy: 0.0000e+00\n",
      "Epoch 163/300\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0038 - accuracy: 0.0062 - val_loss: 0.0151 - val_accuracy: 0.0000e+00\n",
      "Epoch 164/300\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 0.0038 - accuracy: 0.0062 - val_loss: 0.0150 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y, test_x, test_y, scaler =load_data(ddprice, sequence_length=10, split=0.8)\n",
    "# train_x 共 230*0.8=184 筆, test_x 共 230*0.2=46 筆\n",
    "#print(train_x.shape,train_y.shape) # (184,10,1) (184,1)\n",
    "#print(test_x.shape,test_y.shape)   # (46,10,1)  (46,1)\n",
    "predict_y, test_y = train_model(train_x, train_y, test_x, test_y)\n",
    "predict_y = scaler.inverse_transform([[i] for i in predict_y]) # 還原\n",
    "test_y = scaler.inverse_transform(test_y)  # 還原"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[0.26644644],\n",
       "         [0.25409867],\n",
       "         [0.27368954],\n",
       "         ...,\n",
       "         [0.15182917],\n",
       "         [0.        ],\n",
       "         [0.03566364]],\n",
       " \n",
       "        [[0.25409867],\n",
       "         [0.27368954],\n",
       "         [0.25708789],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.03566364],\n",
       "         [0.09417563]],\n",
       " \n",
       "        [[0.27368954],\n",
       "         [0.25708789],\n",
       "         [0.27655612],\n",
       "         ...,\n",
       "         [0.03566364],\n",
       "         [0.09417563],\n",
       "         [0.09770137]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.52939779],\n",
       "         [0.53802819],\n",
       "         [0.34254114],\n",
       "         ...,\n",
       "         [0.30555917],\n",
       "         [0.29904422],\n",
       "         [0.37123761]],\n",
       " \n",
       "        [[0.53802819],\n",
       "         [0.34254114],\n",
       "         [0.38622968],\n",
       "         ...,\n",
       "         [0.29904422],\n",
       "         [0.37123761],\n",
       "         [0.35762518]],\n",
       " \n",
       "        [[0.34254114],\n",
       "         [0.38622968],\n",
       "         [0.29971104],\n",
       "         ...,\n",
       "         [0.37123761],\n",
       "         [0.35762518],\n",
       "         [0.29242962]]]), array([[0.09417563],\n",
       "        [0.09770137],\n",
       "        [0.12729461],\n",
       "        [0.18884946],\n",
       "        [0.15576114],\n",
       "        [0.19100323],\n",
       "        [0.19550238],\n",
       "        [0.22361634],\n",
       "        [0.23954349],\n",
       "        [0.19938836],\n",
       "        [0.25859016],\n",
       "        [0.22697346],\n",
       "        [0.23847811],\n",
       "        [0.2578237 ],\n",
       "        [0.28750125],\n",
       "        [0.25868214],\n",
       "        [0.22232101],\n",
       "        [0.28240425],\n",
       "        [0.34438066],\n",
       "        [0.34451096],\n",
       "        [0.30716875],\n",
       "        [0.33559696],\n",
       "        [0.32210717],\n",
       "        [0.37044049],\n",
       "        [0.32432992],\n",
       "        [0.33388774],\n",
       "        [0.35829201],\n",
       "        [0.32573255],\n",
       "        [0.25511807],\n",
       "        [0.23966613],\n",
       "        [0.26128812],\n",
       "        [0.32560991],\n",
       "        [0.36237727],\n",
       "        [0.39479876],\n",
       "        [0.39102009],\n",
       "        [0.44822908],\n",
       "        [0.46652462],\n",
       "        [0.49128145],\n",
       "        [0.47832052],\n",
       "        [0.46904629],\n",
       "        [0.47809825],\n",
       "        [0.51053507],\n",
       "        [0.52397121],\n",
       "        [0.49327426],\n",
       "        [0.45446811],\n",
       "        [0.49991186],\n",
       "        [0.50536143],\n",
       "        [0.52095134],\n",
       "        [0.53819681],\n",
       "        [0.52633959],\n",
       "        [0.54436686],\n",
       "        [0.53073144],\n",
       "        [0.52194008],\n",
       "        [0.39062153],\n",
       "        [0.41790004],\n",
       "        [0.46572749],\n",
       "        [0.40389671],\n",
       "        [0.46205612],\n",
       "        [0.46443983],\n",
       "        [0.49660073],\n",
       "        [0.48190758],\n",
       "        [0.510788  ],\n",
       "        [0.47920196],\n",
       "        [0.41705693],\n",
       "        [0.42420805],\n",
       "        [0.46806521],\n",
       "        [0.47227311],\n",
       "        [0.47825154],\n",
       "        [0.48702757],\n",
       "        [0.47774567],\n",
       "        [0.45830044],\n",
       "        [0.54047322],\n",
       "        [0.57005112],\n",
       "        [0.59143551],\n",
       "        [0.60612866],\n",
       "        [0.6570373 ],\n",
       "        [0.64729553],\n",
       "        [0.62193318],\n",
       "        [0.65837862],\n",
       "        [0.65569599],\n",
       "        [0.67160781],\n",
       "        [0.66680974],\n",
       "        [0.68848539],\n",
       "        [0.73418973],\n",
       "        [0.73988457],\n",
       "        [0.72060796],\n",
       "        [0.71427695],\n",
       "        [0.71928964],\n",
       "        [0.7481624 ],\n",
       "        [0.77830749],\n",
       "        [0.80657474],\n",
       "        [0.77360139],\n",
       "        [0.7387732 ],\n",
       "        [0.75245461],\n",
       "        [0.74935809],\n",
       "        [0.80974024],\n",
       "        [0.79892542],\n",
       "        [0.86502541],\n",
       "        [0.90246725],\n",
       "        [0.93545593],\n",
       "        [0.96708797],\n",
       "        [0.95468655],\n",
       "        [0.96246618],\n",
       "        [0.97072868],\n",
       "        [0.93930359],\n",
       "        [0.99689581],\n",
       "        [0.94379508],\n",
       "        [0.96254283],\n",
       "        [1.        ],\n",
       "        [0.93527964],\n",
       "        [0.87665269],\n",
       "        [0.87108049],\n",
       "        [0.90173911],\n",
       "        [0.94649304],\n",
       "        [0.96809204],\n",
       "        [0.90045145],\n",
       "        [0.88580429],\n",
       "        [0.86411331],\n",
       "        [0.90637623],\n",
       "        [0.80583893],\n",
       "        [0.76802152],\n",
       "        [0.81683005],\n",
       "        [0.67215967],\n",
       "        [0.67409883],\n",
       "        [0.66449501],\n",
       "        [0.62963616],\n",
       "        [0.69628034],\n",
       "        [0.68877664],\n",
       "        [0.74104193],\n",
       "        [0.74050541],\n",
       "        [0.72226353],\n",
       "        [0.67206003],\n",
       "        [0.75059976],\n",
       "        [0.78453119],\n",
       "        [0.75795783],\n",
       "        [0.85508435],\n",
       "        [0.86314757],\n",
       "        [0.86570756],\n",
       "        [0.93593881],\n",
       "        [0.93040492],\n",
       "        [0.89813672],\n",
       "        [0.95699362],\n",
       "        [0.8701224 ],\n",
       "        [0.90892856],\n",
       "        [0.89248021],\n",
       "        [0.87642275],\n",
       "        [0.89698702],\n",
       "        [0.83784654],\n",
       "        [0.81128084],\n",
       "        [0.73481057],\n",
       "        [0.73042638],\n",
       "        [0.66599729],\n",
       "        [0.71334187],\n",
       "        [0.74542612],\n",
       "        [0.74804743],\n",
       "        [0.66695537],\n",
       "        [0.62882371],\n",
       "        [0.63923997],\n",
       "        [0.57263411],\n",
       "        [0.55594816],\n",
       "        [0.53367467],\n",
       "        [0.53839609],\n",
       "        [0.5562854 ],\n",
       "        [0.54473476],\n",
       "        [0.64521074],\n",
       "        [0.63667231],\n",
       "        [0.59503024],\n",
       "        [0.52939779],\n",
       "        [0.53802819],\n",
       "        [0.34254114],\n",
       "        [0.38622968],\n",
       "        [0.29971104],\n",
       "        [0.28298676],\n",
       "        [0.19039005],\n",
       "        [0.30555917],\n",
       "        [0.29904422],\n",
       "        [0.37123761],\n",
       "        [0.35762518],\n",
       "        [0.29242962],\n",
       "        [0.27845695]]), array([[[0.38622968],\n",
       "         [0.29971104],\n",
       "         [0.28298676],\n",
       "         [0.19039005],\n",
       "         [0.30555917],\n",
       "         [0.29904422],\n",
       "         [0.37123761],\n",
       "         [0.35762518],\n",
       "         [0.29242962],\n",
       "         [0.27845695]],\n",
       " \n",
       "        [[0.29971104],\n",
       "         [0.28298676],\n",
       "         [0.19039005],\n",
       "         [0.30555917],\n",
       "         [0.29904422],\n",
       "         [0.37123761],\n",
       "         [0.35762518],\n",
       "         [0.29242962],\n",
       "         [0.27845695],\n",
       "         [0.39018464]],\n",
       " \n",
       "        [[0.28298676],\n",
       "         [0.19039005],\n",
       "         [0.30555917],\n",
       "         [0.29904422],\n",
       "         [0.37123761],\n",
       "         [0.35762518],\n",
       "         [0.29242962],\n",
       "         [0.27845695],\n",
       "         [0.39018464],\n",
       "         [0.48992481]],\n",
       " \n",
       "        [[0.19039005],\n",
       "         [0.30555917],\n",
       "         [0.29904422],\n",
       "         [0.37123761],\n",
       "         [0.35762518],\n",
       "         [0.29242962],\n",
       "         [0.27845695],\n",
       "         [0.39018464],\n",
       "         [0.48992481],\n",
       "         [0.47796028]],\n",
       " \n",
       "        [[0.30555917],\n",
       "         [0.29904422],\n",
       "         [0.37123761],\n",
       "         [0.35762518],\n",
       "         [0.29242962],\n",
       "         [0.27845695],\n",
       "         [0.39018464],\n",
       "         [0.48992481],\n",
       "         [0.47796028],\n",
       "         [0.54440518]],\n",
       " \n",
       "        [[0.29904422],\n",
       "         [0.37123761],\n",
       "         [0.35762518],\n",
       "         [0.29242962],\n",
       "         [0.27845695],\n",
       "         [0.39018464],\n",
       "         [0.48992481],\n",
       "         [0.47796028],\n",
       "         [0.54440518],\n",
       "         [0.5674758 ]],\n",
       " \n",
       "        [[0.37123761],\n",
       "         [0.35762518],\n",
       "         [0.29242962],\n",
       "         [0.27845695],\n",
       "         [0.39018464],\n",
       "         [0.48992481],\n",
       "         [0.47796028],\n",
       "         [0.54440518],\n",
       "         [0.5674758 ],\n",
       "         [0.55545762]],\n",
       " \n",
       "        [[0.35762518],\n",
       "         [0.29242962],\n",
       "         [0.27845695],\n",
       "         [0.39018464],\n",
       "         [0.48992481],\n",
       "         [0.47796028],\n",
       "         [0.54440518],\n",
       "         [0.5674758 ],\n",
       "         [0.55545762],\n",
       "         [0.53508496]],\n",
       " \n",
       "        [[0.29242962],\n",
       "         [0.27845695],\n",
       "         [0.39018464],\n",
       "         [0.48992481],\n",
       "         [0.47796028],\n",
       "         [0.54440518],\n",
       "         [0.5674758 ],\n",
       "         [0.55545762],\n",
       "         [0.53508496],\n",
       "         [0.48022136]],\n",
       " \n",
       "        [[0.27845695],\n",
       "         [0.39018464],\n",
       "         [0.48992481],\n",
       "         [0.47796028],\n",
       "         [0.54440518],\n",
       "         [0.5674758 ],\n",
       "         [0.55545762],\n",
       "         [0.53508496],\n",
       "         [0.48022136],\n",
       "         [0.49677701]],\n",
       " \n",
       "        [[0.39018464],\n",
       "         [0.48992481],\n",
       "         [0.47796028],\n",
       "         [0.54440518],\n",
       "         [0.5674758 ],\n",
       "         [0.55545762],\n",
       "         [0.53508496],\n",
       "         [0.48022136],\n",
       "         [0.49677701],\n",
       "         [0.60205873]],\n",
       " \n",
       "        [[0.48992481],\n",
       "         [0.47796028],\n",
       "         [0.54440518],\n",
       "         [0.5674758 ],\n",
       "         [0.55545762],\n",
       "         [0.53508496],\n",
       "         [0.48022136],\n",
       "         [0.49677701],\n",
       "         [0.60205873],\n",
       "         [0.58991791]],\n",
       " \n",
       "        [[0.47796028],\n",
       "         [0.54440518],\n",
       "         [0.5674758 ],\n",
       "         [0.55545762],\n",
       "         [0.53508496],\n",
       "         [0.48022136],\n",
       "         [0.49677701],\n",
       "         [0.60205873],\n",
       "         [0.58991791],\n",
       "         [0.50162874]],\n",
       " \n",
       "        [[0.54440518],\n",
       "         [0.5674758 ],\n",
       "         [0.55545762],\n",
       "         [0.53508496],\n",
       "         [0.48022136],\n",
       "         [0.49677701],\n",
       "         [0.60205873],\n",
       "         [0.58991791],\n",
       "         [0.50162874],\n",
       "         [0.548935  ]],\n",
       " \n",
       "        [[0.5674758 ],\n",
       "         [0.55545762],\n",
       "         [0.53508496],\n",
       "         [0.48022136],\n",
       "         [0.49677701],\n",
       "         [0.60205873],\n",
       "         [0.58991791],\n",
       "         [0.50162874],\n",
       "         [0.548935  ],\n",
       "         [0.55062889]],\n",
       " \n",
       "        [[0.55545762],\n",
       "         [0.53508496],\n",
       "         [0.48022136],\n",
       "         [0.49677701],\n",
       "         [0.60205873],\n",
       "         [0.58991791],\n",
       "         [0.50162874],\n",
       "         [0.548935  ],\n",
       "         [0.55062889],\n",
       "         [0.47513969]],\n",
       " \n",
       "        [[0.53508496],\n",
       "         [0.48022136],\n",
       "         [0.49677701],\n",
       "         [0.60205873],\n",
       "         [0.58991791],\n",
       "         [0.50162874],\n",
       "         [0.548935  ],\n",
       "         [0.55062889],\n",
       "         [0.47513969],\n",
       "         [0.45573278]],\n",
       " \n",
       "        [[0.48022136],\n",
       "         [0.49677701],\n",
       "         [0.60205873],\n",
       "         [0.58991791],\n",
       "         [0.50162874],\n",
       "         [0.548935  ],\n",
       "         [0.55062889],\n",
       "         [0.47513969],\n",
       "         [0.45573278],\n",
       "         [0.5355755 ]],\n",
       " \n",
       "        [[0.49677701],\n",
       "         [0.60205873],\n",
       "         [0.58991791],\n",
       "         [0.50162874],\n",
       "         [0.548935  ],\n",
       "         [0.55062889],\n",
       "         [0.47513969],\n",
       "         [0.45573278],\n",
       "         [0.5355755 ],\n",
       "         [0.62420192]],\n",
       " \n",
       "        [[0.60205873],\n",
       "         [0.58991791],\n",
       "         [0.50162874],\n",
       "         [0.548935  ],\n",
       "         [0.55062889],\n",
       "         [0.47513969],\n",
       "         [0.45573278],\n",
       "         [0.5355755 ],\n",
       "         [0.62420192],\n",
       "         [0.63390537]],\n",
       " \n",
       "        [[0.58991791],\n",
       "         [0.50162874],\n",
       "         [0.548935  ],\n",
       "         [0.55062889],\n",
       "         [0.47513969],\n",
       "         [0.45573278],\n",
       "         [0.5355755 ],\n",
       "         [0.62420192],\n",
       "         [0.63390537],\n",
       "         [0.65751251]],\n",
       " \n",
       "        [[0.50162874],\n",
       "         [0.548935  ],\n",
       "         [0.55062889],\n",
       "         [0.47513969],\n",
       "         [0.45573278],\n",
       "         [0.5355755 ],\n",
       "         [0.62420192],\n",
       "         [0.63390537],\n",
       "         [0.65751251],\n",
       "         [0.65284474]],\n",
       " \n",
       "        [[0.548935  ],\n",
       "         [0.55062889],\n",
       "         [0.47513969],\n",
       "         [0.45573278],\n",
       "         [0.5355755 ],\n",
       "         [0.62420192],\n",
       "         [0.63390537],\n",
       "         [0.65751251],\n",
       "         [0.65284474],\n",
       "         [0.6575585 ]],\n",
       " \n",
       "        [[0.55062889],\n",
       "         [0.47513969],\n",
       "         [0.45573278],\n",
       "         [0.5355755 ],\n",
       "         [0.62420192],\n",
       "         [0.63390537],\n",
       "         [0.65751251],\n",
       "         [0.65284474],\n",
       "         [0.6575585 ],\n",
       "         [0.6904552 ]],\n",
       " \n",
       "        [[0.47513969],\n",
       "         [0.45573278],\n",
       "         [0.5355755 ],\n",
       "         [0.62420192],\n",
       "         [0.63390537],\n",
       "         [0.65751251],\n",
       "         [0.65284474],\n",
       "         [0.6575585 ],\n",
       "         [0.6904552 ],\n",
       "         [0.70719481]],\n",
       " \n",
       "        [[0.45573278],\n",
       "         [0.5355755 ],\n",
       "         [0.62420192],\n",
       "         [0.63390537],\n",
       "         [0.65751251],\n",
       "         [0.65284474],\n",
       "         [0.6575585 ],\n",
       "         [0.6904552 ],\n",
       "         [0.70719481],\n",
       "         [0.65397144]],\n",
       " \n",
       "        [[0.5355755 ],\n",
       "         [0.62420192],\n",
       "         [0.63390537],\n",
       "         [0.65751251],\n",
       "         [0.65284474],\n",
       "         [0.6575585 ],\n",
       "         [0.6904552 ],\n",
       "         [0.70719481],\n",
       "         [0.65397144],\n",
       "         [0.59041611]],\n",
       " \n",
       "        [[0.62420192],\n",
       "         [0.63390537],\n",
       "         [0.65751251],\n",
       "         [0.65284474],\n",
       "         [0.6575585 ],\n",
       "         [0.6904552 ],\n",
       "         [0.70719481],\n",
       "         [0.65397144],\n",
       "         [0.59041611],\n",
       "         [0.69808154]],\n",
       " \n",
       "        [[0.63390537],\n",
       "         [0.65751251],\n",
       "         [0.65284474],\n",
       "         [0.6575585 ],\n",
       "         [0.6904552 ],\n",
       "         [0.70719481],\n",
       "         [0.65397144],\n",
       "         [0.59041611],\n",
       "         [0.69808154],\n",
       "         [0.73628985]],\n",
       " \n",
       "        [[0.65751251],\n",
       "         [0.65284474],\n",
       "         [0.6575585 ],\n",
       "         [0.6904552 ],\n",
       "         [0.70719481],\n",
       "         [0.65397144],\n",
       "         [0.59041611],\n",
       "         [0.69808154],\n",
       "         [0.73628985],\n",
       "         [0.72207957]],\n",
       " \n",
       "        [[0.65284474],\n",
       "         [0.6575585 ],\n",
       "         [0.6904552 ],\n",
       "         [0.70719481],\n",
       "         [0.65397144],\n",
       "         [0.59041611],\n",
       "         [0.69808154],\n",
       "         [0.73628985],\n",
       "         [0.72207957],\n",
       "         [0.70730212]],\n",
       " \n",
       "        [[0.6575585 ],\n",
       "         [0.6904552 ],\n",
       "         [0.70719481],\n",
       "         [0.65397144],\n",
       "         [0.59041611],\n",
       "         [0.69808154],\n",
       "         [0.73628985],\n",
       "         [0.72207957],\n",
       "         [0.70730212],\n",
       "         [0.66254819]],\n",
       " \n",
       "        [[0.6904552 ],\n",
       "         [0.70719481],\n",
       "         [0.65397144],\n",
       "         [0.59041611],\n",
       "         [0.69808154],\n",
       "         [0.73628985],\n",
       "         [0.72207957],\n",
       "         [0.70730212],\n",
       "         [0.66254819],\n",
       "         [0.58840031]],\n",
       " \n",
       "        [[0.70719481],\n",
       "         [0.65397144],\n",
       "         [0.59041611],\n",
       "         [0.69808154],\n",
       "         [0.73628985],\n",
       "         [0.72207957],\n",
       "         [0.70730212],\n",
       "         [0.66254819],\n",
       "         [0.58840031],\n",
       "         [0.57376848]],\n",
       " \n",
       "        [[0.65397144],\n",
       "         [0.59041611],\n",
       "         [0.69808154],\n",
       "         [0.73628985],\n",
       "         [0.72207957],\n",
       "         [0.70730212],\n",
       "         [0.66254819],\n",
       "         [0.58840031],\n",
       "         [0.57376848],\n",
       "         [0.58469828]],\n",
       " \n",
       "        [[0.59041611],\n",
       "         [0.69808154],\n",
       "         [0.73628985],\n",
       "         [0.72207957],\n",
       "         [0.70730212],\n",
       "         [0.66254819],\n",
       "         [0.58840031],\n",
       "         [0.57376848],\n",
       "         [0.58469828],\n",
       "         [0.55273667]],\n",
       " \n",
       "        [[0.69808154],\n",
       "         [0.73628985],\n",
       "         [0.72207957],\n",
       "         [0.70730212],\n",
       "         [0.66254819],\n",
       "         [0.58840031],\n",
       "         [0.57376848],\n",
       "         [0.58469828],\n",
       "         [0.55273667],\n",
       "         [0.52612498]],\n",
       " \n",
       "        [[0.73628985],\n",
       "         [0.72207957],\n",
       "         [0.70730212],\n",
       "         [0.66254819],\n",
       "         [0.58840031],\n",
       "         [0.57376848],\n",
       "         [0.58469828],\n",
       "         [0.55273667],\n",
       "         [0.52612498],\n",
       "         [0.43219462]],\n",
       " \n",
       "        [[0.72207957],\n",
       "         [0.70730212],\n",
       "         [0.66254819],\n",
       "         [0.58840031],\n",
       "         [0.57376848],\n",
       "         [0.58469828],\n",
       "         [0.55273667],\n",
       "         [0.52612498],\n",
       "         [0.43219462],\n",
       "         [0.47072485]],\n",
       " \n",
       "        [[0.70730212],\n",
       "         [0.66254819],\n",
       "         [0.58840031],\n",
       "         [0.57376848],\n",
       "         [0.58469828],\n",
       "         [0.55273667],\n",
       "         [0.52612498],\n",
       "         [0.43219462],\n",
       "         [0.47072485],\n",
       "         [0.56338287]],\n",
       " \n",
       "        [[0.66254819],\n",
       "         [0.58840031],\n",
       "         [0.57376848],\n",
       "         [0.58469828],\n",
       "         [0.55273667],\n",
       "         [0.52612498],\n",
       "         [0.43219462],\n",
       "         [0.47072485],\n",
       "         [0.56338287],\n",
       "         [0.63656501]],\n",
       " \n",
       "        [[0.58840031],\n",
       "         [0.57376848],\n",
       "         [0.58469828],\n",
       "         [0.55273667],\n",
       "         [0.52612498],\n",
       "         [0.43219462],\n",
       "         [0.47072485],\n",
       "         [0.56338287],\n",
       "         [0.63656501],\n",
       "         [0.63864213]],\n",
       " \n",
       "        [[0.57376848],\n",
       "         [0.58469828],\n",
       "         [0.55273667],\n",
       "         [0.52612498],\n",
       "         [0.43219462],\n",
       "         [0.47072485],\n",
       "         [0.56338287],\n",
       "         [0.63656501],\n",
       "         [0.63864213],\n",
       "         [0.70645134]],\n",
       " \n",
       "        [[0.58469828],\n",
       "         [0.55273667],\n",
       "         [0.52612498],\n",
       "         [0.43219462],\n",
       "         [0.47072485],\n",
       "         [0.56338287],\n",
       "         [0.63656501],\n",
       "         [0.63864213],\n",
       "         [0.70645134],\n",
       "         [0.68538887]],\n",
       " \n",
       "        [[0.55273667],\n",
       "         [0.52612498],\n",
       "         [0.43219462],\n",
       "         [0.47072485],\n",
       "         [0.56338287],\n",
       "         [0.63656501],\n",
       "         [0.63864213],\n",
       "         [0.70645134],\n",
       "         [0.68538887],\n",
       "         [0.72782807]],\n",
       " \n",
       "        [[0.52612498],\n",
       "         [0.43219462],\n",
       "         [0.47072485],\n",
       "         [0.56338287],\n",
       "         [0.63656501],\n",
       "         [0.63864213],\n",
       "         [0.70645134],\n",
       "         [0.68538887],\n",
       "         [0.72782807],\n",
       "         [0.73122351]]]), array([[0.39018464],\n",
       "        [0.48992481],\n",
       "        [0.47796028],\n",
       "        [0.54440518],\n",
       "        [0.5674758 ],\n",
       "        [0.55545762],\n",
       "        [0.53508496],\n",
       "        [0.48022136],\n",
       "        [0.49677701],\n",
       "        [0.60205873],\n",
       "        [0.58991791],\n",
       "        [0.50162874],\n",
       "        [0.548935  ],\n",
       "        [0.55062889],\n",
       "        [0.47513969],\n",
       "        [0.45573278],\n",
       "        [0.5355755 ],\n",
       "        [0.62420192],\n",
       "        [0.63390537],\n",
       "        [0.65751251],\n",
       "        [0.65284474],\n",
       "        [0.6575585 ],\n",
       "        [0.6904552 ],\n",
       "        [0.70719481],\n",
       "        [0.65397144],\n",
       "        [0.59041611],\n",
       "        [0.69808154],\n",
       "        [0.73628985],\n",
       "        [0.72207957],\n",
       "        [0.70730212],\n",
       "        [0.66254819],\n",
       "        [0.58840031],\n",
       "        [0.57376848],\n",
       "        [0.58469828],\n",
       "        [0.55273667],\n",
       "        [0.52612498],\n",
       "        [0.43219462],\n",
       "        [0.47072485],\n",
       "        [0.56338287],\n",
       "        [0.63656501],\n",
       "        [0.63864213],\n",
       "        [0.70645134],\n",
       "        [0.68538887],\n",
       "        [0.72782807],\n",
       "        [0.73122351],\n",
       "        [0.78317455]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x, train_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8718.45121648],\n",
       "       [8728.62451018],\n",
       "       [8782.36954953],\n",
       "       [8844.87775924],\n",
       "       [8914.42414313],\n",
       "       [8978.40756596],\n",
       "       [9018.62605963],\n",
       "       [9028.66536323],\n",
       "       [9002.55657935],\n",
       "       [8969.40993236],\n",
       "       [8977.85465266],\n",
       "       [9007.13261738],\n",
       "       [9009.16307678],\n",
       "       [9006.13161878],\n",
       "       [9003.94562822],\n",
       "       [8979.31057992],\n",
       "       [8941.30195086],\n",
       "       [8932.19474555],\n",
       "       [8972.16438935],\n",
       "       [9032.85560619],\n",
       "       [9093.6736587 ],\n",
       "       [9134.99914545],\n",
       "       [9155.25225861],\n",
       "       [9170.37424302],\n",
       "       [9186.0360761 ],\n",
       "       [9181.06631092],\n",
       "       [9143.82888315],\n",
       "       [9133.94394424],\n",
       "       [9159.37367903],\n",
       "       [9192.42949582],\n",
       "       [9212.89623105],\n",
       "       [9203.75449782],\n",
       "       [9155.03078223],\n",
       "       [9093.35349779],\n",
       "       [9048.30894974],\n",
       "       [9016.53113256],\n",
       "       [8991.17255328],\n",
       "       [8945.09061234],\n",
       "       [8909.11633096],\n",
       "       [8919.51825547],\n",
       "       [8977.59273817],\n",
       "       [9046.59779583],\n",
       "       [9122.38222381],\n",
       "       [9175.64690514],\n",
       "       [9214.45558654],\n",
       "       [9237.70889593]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.39018464],\n",
       "       [0.48992481],\n",
       "       [0.47796028],\n",
       "       [0.54440518],\n",
       "       [0.5674758 ],\n",
       "       [0.55545762],\n",
       "       [0.53508496],\n",
       "       [0.48022136],\n",
       "       [0.49677701],\n",
       "       [0.60205873],\n",
       "       [0.58991791],\n",
       "       [0.50162874],\n",
       "       [0.548935  ],\n",
       "       [0.55062889],\n",
       "       [0.47513969],\n",
       "       [0.45573278],\n",
       "       [0.5355755 ],\n",
       "       [0.62420192],\n",
       "       [0.63390537],\n",
       "       [0.65751251],\n",
       "       [0.65284474],\n",
       "       [0.6575585 ],\n",
       "       [0.6904552 ],\n",
       "       [0.70719481],\n",
       "       [0.65397144],\n",
       "       [0.59041611],\n",
       "       [0.69808154],\n",
       "       [0.73628985],\n",
       "       [0.72207957],\n",
       "       [0.70730212],\n",
       "       [0.66254819],\n",
       "       [0.58840031],\n",
       "       [0.57376848],\n",
       "       [0.58469828],\n",
       "       [0.55273667],\n",
       "       [0.52612498],\n",
       "       [0.43219462],\n",
       "       [0.47072485],\n",
       "       [0.56338287],\n",
       "       [0.63656501],\n",
       "       [0.63864213],\n",
       "       [0.70645134],\n",
       "       [0.68538887],\n",
       "       [0.72782807],\n",
       "       [0.73122351],\n",
       "       [0.78317455]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
