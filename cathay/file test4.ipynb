{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from plotly.graph_objs import Scatter, Layout\n",
    "from plotly.offline import plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(df, sequence_length=10, split=0.8):\n",
    "    data_all = np.array(df).astype(float)    # 轉為浮點型別矩陣\n",
    "    #print(data_all.shape) # (241,1)\n",
    "    scaler = MinMaxScaler()\n",
    "    data_all = scaler.fit_transform(data_all)  # 將數據縮放為 0~1 之間\n",
    "    data = []\n",
    "    # data 資料共有 (241-10-1)=230 筆\n",
    "    for i in range(len(data_all) - sequence_length - 1):\n",
    "        # 每筆 data 資料有 11 欄\n",
    "        data.append(data_all[i: i + sequence_length + 1])\n",
    "    reshaped_data = np.array(data).astype('float64')\n",
    "\n",
    "    x = reshaped_data[:, :-1] # 第 1至第10個欄位為 特徵\n",
    "    y = reshaped_data[:, -1]  # 第 11個欄位為 label\n",
    "    #print(x.shape,y.shape) # (230,10,1) (230,1)\n",
    "    split_boundary = int(reshaped_data.shape[0] * split)\n",
    "    train_x = x[: split_boundary] # 前 80% 為 train 的特徵\n",
    "    test_x = x[split_boundary:]   # 最後 20% 為 test 的特徵\n",
    " \n",
    "    train_y = y[: split_boundary] # 前 80% 為 train 的 label\n",
    "    test_y = y[split_boundary:]   # 最後 20% 為 test 的 label\n",
    "\n",
    "    return train_x, train_y, test_x, test_y, scaler\n",
    "\n",
    "def build_model():\n",
    "    model = Sequential()     \n",
    "    # 隱藏層：256 個神經元，input_shape：(10,1)\n",
    "    # TIME_STEPS=10,INPUT_SIZE=1\n",
    "    model.add(LSTM(input_shape=(10,1),units=256,unroll=False))\n",
    "    model.add(Dense(units=1)) # 輸出層：1 個神經元\n",
    "    #compile:loss, optimizer, metrics\n",
    "    model.compile(loss=\"mse\", optimizer=\"adam\", metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def train_model(train_x, train_y, test_x, test_y):\n",
    "    model = build_model()\n",
    "    try:\n",
    "        model.fit(train_x, train_y, batch_size=100, epochs=300, validation_split=0.1)\n",
    "        predict = model.predict(test_x)\n",
    "        predict = np.reshape(predict, (predict.size, )) #轉換為1維矩陣\n",
    "    except KeyboardInterrupt:\n",
    "        print(predict)\n",
    "        print(test_y)\n",
    "    return predict, test_y #傳回 預測值和真實值\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>收盤價</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>9.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>57.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>29.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>34.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>24.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>405205</td>\n",
       "      <td>102.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>405206</td>\n",
       "      <td>94.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>405207</td>\n",
       "      <td>98.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>405208</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>405209</td>\n",
       "      <td>1063.77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>405210 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            收盤價\n",
       "0          9.04\n",
       "1         57.60\n",
       "2         29.50\n",
       "3         34.76\n",
       "4         24.30\n",
       "...         ...\n",
       "405205   102.20\n",
       "405206    94.86\n",
       "405207    98.22\n",
       "405208      NaN\n",
       "405209  1063.77\n",
       "\n",
       "[405210 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 主程式\n",
    "pd.options.mode.chained_assignment = None  #取消顯示pandas資料重設警告\n",
    "filename = './data/Train_X.csv'\n",
    "df = pd.read_csv(filename, encoding='cp950')  #以pandas讀取檔案\n",
    "ddprice=pd.DataFrame(df['收盤價'])\n",
    "ddprice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 255275 samples, validate on 28364 samples\n",
      "Epoch 1/300\n",
      "255275/255275 [==============================] - 840s 3ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00 - E - ETA:  - ETA: 7s - loss: nan - accuracy: 0 - ETA: 4s - loss: nan - accura\n",
      "Epoch 2/300\n",
      "255275/255275 [==============================] - 395s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00 - loss: nan - accurac - ETA: 9:00 - loss: nan - accu - ETA: 6:52 - ETA: 6:54 - loss: nan - accurac - ETA: 6:45 - loss: nan - ac - ETA: 6:35 - loss: n - ETA: 6:29 - loss: nan - accuracy:  - ETA: 6:24 - loss: nan - accuracy: 0.0000e+0 - ETA: 6:23 - loss: nan - accu - ETA: 6:15 - loss: nan - accuracy: 0.0000e+0 - ETA: 6:15 - loss: nan - accuracy: 0. - ETA: 6:11 - loss: nan - accuracy: 0.000 - ETA: 6:0 - ETA: 5:38 - loss: - ETA: 5 - ETA: 5:44 - loss: nan - accuracy: 0.0 - ETA: 5:33 - loss: nan - accuracy: 0.0 - ETA: 5:30 - loss: nan - accuracy: 0.0000e+ - ETA: 5:29 - loss: nan - accuracy: 0. - ETA: 5:26 - loss: nan - accuracy: 0.0000e+0 - ETA: 5:25 - loss: nan - accuracy: - ETA: 5:21 - loss: nan - accuracy:  - ETA: 5:19 - loss: nan - accuracy: 0.0000e+0 - ETA:  - ETA: 5:05 - loss: nan - accuracy: 0.00 - ETA: 5:04 - loss: nan - accuracy: 0.000 - ETA: 5:03 - loss: nan - accura - ETA: 4:58 - loss: nan - accuracy: 0.0000 - ETA: 4:57 - loss: nan - accuracy: 0.0000e+0 - ETA: 4:56 - loss: nan - accuracy: 0.0000e+ - ETA: 4:56 - loss: nan - accu - ETA: 4:50 - loss: nan - accuracy - ETA: 4:46 - loss: n - ETA: 4:38 - loss: nan - accuracy:  - ETA: 4:35 - loss: nan - accuracy: 0.0000e - ETA: 4:34 - loss: nan - accur - ETA: 4:30 - loss: nan - ETA: 4:24 - loss: na - ETA: 4:18 - loss: nan - accuracy: 0.0000e+ - ETA: 4:17 - loss: nan - accuracy: 0.0000e+0 - ETA: 4:17 - loss: nan - ETA: 4:11 - ET - ETA: 4:07 - loss: nan - accuracy: 0.0000e+0 - ETA: 4:07 - loss: nan - accuracy: 0.00 - ETA: 4:06 - loss: nan - accuracy: 0.000 - ETA: 4:04 - loss: nan - accuracy: 0.000 - ETA: 4:03 - loss: nan - accura - ETA: 4:00 - loss: nan - accuracy: 0.00 - ETA: 3:58 - loss: nan - accur - ETA: 3:55 - loss: nan - accuracy: 0. - ETA: 3:54 - loss: nan - accuracy: 0.0000e - ETA: 3:53 - loss: nan - accuracy: 0.000 - ETA: 3:52 - loss: nan - accuracy: 0.0000e+0 - ETA: 3:52 - loss: nan - accuracy: 0.0000e+0 - ETA: 3:52 - loss: nan - accuracy: 0.0000e+0 - ETA: 3:51 - loss: nan - accuracy: 0.00 - ETA: 3:50 - loss: nan - accuracy: 0.000 - ETA: 3:48 - loss: nan - accuracy: 0.0000e+0 - ETA: 3:48 - loss: nan - accuracy: 0.0000e+ - ETA: 3:48 - loss: nan - accuracy: 0.0000e - ETA: 3:47 - loss: nan - accuracy: 0.0000e - ETA: 3:46 - loss: nan - accuracy: 0 - ETA: 3:44 - loss: nan - accuracy: 0 - ETA: 3:42 - loss: nan - accuracy: 0.0000e+ - ETA: 3:42 - loss: nan - accur - ETA: 3:38 - loss: nan - ETA: 3:33 - loss: nan - accuracy: - ETA: 3:30 - loss: nan - accuracy: 0.000 - ETA: 3:30 - loss: nan - accuracy: 0.0000e+ - ETA: 3:30 - loss: nan - accuracy: 0. - ETA: 3:28 - loss: nan - accuracy: 0 - ETA: 3:26 - loss: nan - accuracy: 0.0000e+0 - ETA: 3:25 - loss: nan - accuracy: 0.0000 - ETA: 3:25 - loss: nan - accuracy: 0.0 - ETA: 3:23 - loss: nan - accuracy: 0.0000e+0 - ETA: 3:23 - loss: nan - accuracy: 0.0000e+0 - ETA: 3:22 - loss: nan - accuracy: 0 - ETA: 3:21 - loss: nan - accuracy: 0. - ETA: 3:19 - loss: nan - accuracy: 0. - ETA: 3:17 - loss: nan - accuracy: 0.0000e - ETA: 3:16 - loss: nan - accuracy: 0.0000e+0 - ETA: 3:16 - loss: nan - accuracy - ETA: 3:15 - loss: nan - accuracy: 0.0000e+ - ETA: 3:14 - loss: nan - accuracy: 0.0000e+ - ETA: 3:14 - loss: nan - accuracy: 0.0000e+0 - ETA: 3:13 - loss: nan - accuracy: 0.0000e+0 - ETA: 3:13 - loss: nan - accuracy: 0.0000 - ETA: 3:12 - loss: nan - accuracy:  - ETA: 3:10 - loss: nan - accuracy: 0.0000e+ - ETA: 3:10 - loss: nan - accuracy: 0.0000e - ETA: 3:09 - loss: nan - accuracy: 0.0000e - ETA: 3:08 - loss: nan - accuracy: 0. - ETA: 3:07 - loss: nan - accuracy: 0.0000e+ - ETA: 3:06 - loss: nan - accuracy: 0.00 - ETA: 3:06 - loss: nan - accuracy: 0 - ETA: 3:03 - loss: nan - accuracy: 0.0 - ETA: 3:02 - loss: nan - accuracy: 0.0000 - ETA: 3:01 - loss: nan - accuracy: 0.0000e+0 - ETA: 3:01 - loss: nan - accuracy: 0.0000e+0 - ETA: 3:01 - loss: nan - accuracy: 0.0000e - ETA: 3:00 - loss: nan - accuracy: 0.0000 - ETA: 2:59 - loss: nan - accuracy: 0.0000e+0 - ETA: 2:59 - loss: nan - accuracy: 0.0000 - ETA: 2:58 - loss: nan - accuracy: 0.0000e+0 - ETA: 2:58 - loss: nan - accuracy: 0.00 - ETA: 2:57 - loss: nan - accuracy: 0.0000e+ - ETA: 2:56 - loss: nan - acc - ETA: 2:53 - loss: nan - accuracy: 0.0000e+ - ETA: 2:52 - loss: nan - accuracy: 0. - ETA: 2:51 - loss: nan - accuracy: 0.0000e+0 - ETA: 2:51 - loss: nan - accuracy: 0.0000e+0 - ETA: 2:50 - loss: nan - acc - ETA: 2:47 - loss: nan - accu - ETA: 2:44 - loss: nan - accura - ETA: 2:43 - loss: nan - accuracy: 0.0000e - ETA: 2:42 - loss: nan - accuracy: 0. - ETA: 2:41 - loss: nan - accuracy: 0.0000e+0 - ETA: 2:40 - loss: nan - accuracy: 0.0000 - ETA: 2:39 - loss: nan - accuracy: 0.0000e+0 - ETA: 2:39 - loss: nan - accuracy: 0.0000e+0 - ETA: 2:39 -  - ETA: 2:34 - loss: nan - accuracy: 0.0000e+0 - ETA: 2:34 - loss: nan - accuracy: 0.0 - ETA: 2:33 - loss: nan - accuracy: 0.0000e+0 - ETA: 2:32 - loss: nan - accuracy: 0.0000e+0 - ETA: 2:32 - loss: nan - accuracy: 0.000 - ETA: 2:31 - loss: nan - accuracy: 0.0000 - ETA: 2:30 - loss: nan - accuracy: 0.0000e+ - ETA: 2:30 - loss: nan - accuracy: 0.0000 - ETA: 2:29 - loss: nan - accuracy: 0.0000e - ETA: 2:29 - loss: nan - accuracy: 0.0000e+0 - ETA: 2:28 - loss: nan - accuracy - ETA: 2:27 - loss - ETA: 2:22 - ETA: 1:57 - loss: nan - accuracy: - ETA: 1:55 - loss: nan - accu - ETA: 1:52 - loss: nan - accuracy: 0.0000 - ETA: 1:51 - loss: nan - accuracy: 0.00 - ETA: 1:50 - loss: n - ETA: 1:45 -  - ETA: 1:40 - l - ETA: 1:34 - - ETA: 1:28 - loss: nan - accuracy: 0. - ETA: 1:26 - loss: nan - accuracy - ETA: 1:24 - loss: nan - acc - ETA: 1:21 - loss: nan - accu - ETA: 1:10 - loss: nan  - ETA: 1:06 - loss: nan - accuracy: 0.0000e+0 - ETA: 1:06 - loss: nan - accuracy: 0.000 - ETA: 1:05 - loss: nan - accura - ETA: 1:03 - loss: nan - accuracy: 0.000 - ETA: 1:02 - loss: nan - accuracy: 0. - ETA: 1:01 - loss: nan - accuracy: 0.0000e+ - ETA: 1:00 - loss: nan - accuracy - ETA: 59s - loss: nan - accuracy: 0.0000e+ - ETA: 43s - loss: nan  - ETA: 42s - loss: nan - accuracy - ETA - E - ETA: 34s - loss: nan - accuracy: 0.0000 - ETA: 34s - loss: nan - accura - ETA: 32s - loss: nan - accuracy: 0.0000e+ - ETA: 32s - loss: nan - accuracy: 0.0000 - ETA: 32s - loss: nan - accuracy: 0.00 - ETA: 32s - loss: nan - accuracy: 0.00 - ETA: 31s - loss: nan - accuracy: 0. - ETA: 30s - loss: nan - accura - ETA: 29s - loss: nan - accuracy: 0.00 - ETA: 29s - loss: nan - accuracy: 0.0000e+ - ETA: 29s - loss: nan - accuracy: 0.00 - ETA: 28s - loss: nan - accuracy: 0.0000 - ETA: 28s - loss: nan - accuracy: 0. - ETA: 27s - loss: nan - accuracy - ETA: 26s - loss: nan - accuracy: 0.0000e+ - ETA: 26s - loss: nan - accuracy: 0.0000e+ - ETA: 26s - loss: nan - accura - ETA: - ETA: 6s - - ETA: 1s - loss: nan - accuracy: 0.0\n",
      "Epoch 3/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206900/255275 [=======================>......] - ETA: 1:03 - loss: nan - accuracy: 0.0000e+00- ETA: 3: - ETA: 4:49 - loss: nan - accuracy: 0.0 - ETA: 4:48 - ETA: 4:30 - loss: na - ETA: 6:42 - loss: - ETA: 6:25 - loss: nan - accur - ETA: 6:16 - loss: nan - accuracy - ETA: 6:09 - loss: nan  - ETA: 5:58 - loss: nan - accuracy: 0.0000e+0 - ETA: 5:57 - loss: nan - accur - ETA: 5:50 - loss: nan - accuracy: 0.0000e - ETA: 5:49 - loss: nan - accura - ETA: 5:49 - loss: nan - accuracy: 0.000 - ETA: 5:48 - loss: nan - accuracy: 0.0000e+ - ETA: 5:47 - loss: nan - accu - ETA: 5:39 - loss: nan - accuracy: 0.0000e - ETA: 5:38 - loss: nan - accuracy: 0.0000e+ - ETA: 5:37 - loss: nan - accuracy - ETA: 5 - ETA: 5:17 - loss: nan - accuracy: 0.0000e+0 - ETA: 5:17 - loss: nan - accuracy: 0.00 - ETA: 5:15 - loss: nan - accuracy: 0.0000e+ - ETA: 5:14 - loss: nan - accuracy: 0.0000e+0 - ETA: 5:14 - loss: nan - accuracy: 0 - ETA: 5:11 - loss: nan - acc - ETA: 5:06 - loss: nan - accuracy: 0.0000e+0 - ETA: 5:06 - loss: n - ETA: 5:01 - loss: nan - accuracy: 0. - ETA: 4:59 - loss: nan - accuracy: 0.0000e+0 - ETA: 4:58 - loss: nan - accuracy: 0.0 - ETA: 4:56 - loss: nan - accuracy: 0.0000e - ETA: 4:55 - loss: nan - ac - ETA: 4:49 - loss: nan - accuracy: 0.0000e+0 - ETA: 4:49 - l - ETA: 4:26 - loss: n - ETA: 4:23 - loss: nan - accurac - ETA: 4:19 - loss: nan - accuracy: 0.00 - ETA: 4:18 - loss: nan - accuracy: 0.0000e - ETA: 4:17 - loss: n - ETA: 4:12 - loss: nan - a - ETA: 4:08 - loss: nan - accuracy: 0.0000e - ETA: 4:08 - loss: nan - accuracy: 0.0 - ETA: 4:06 - loss: nan - accuracy: 0.00 - ETA: 4:05 - loss: nan - accuracy: - ETA: 4:03 - los - ETA: 3:56 - loss: - ETA: 3:53 - loss: nan - accuracy: 0.0000e+ - ETA: 3:53 - loss: nan - accuracy:  - ETA: 3:51 - loss: nan - accur - ETA: 3:47 - loss: nan - - ETA: 3:43 - loss: nan - accuracy: 0.0000e+0 - ETA: 3:43 - loss: nan - accur - ETA: 3:40 - loss: nan - accuracy: 0.0 - ETA: 3:38 - loss: nan - accura - ETA: 3:36 - loss: nan - accu - ETA: 3:33 - loss: nan - accuracy: 0.0000e - ETA: 3:32 - loss: nan - accuracy: 0.0000e+0 - ETA: 3:32 - loss: nan - accuracy: 0.0000e+ - ETA: 3:32 - loss: nan - accuracy: 0. - ETA: 3:30 - loss: nan - accuracy: 0.0000 - - ETA: 3:29 - loss: nan - accuracy: 0.0 - ETA: 3:28 - loss: nan - accuracy: 0.00 - ETA: 3:27 - loss: nan - accuracy: 0.0000e+ - ETA: 3:26 - loss: nan - accuracy: 0.0000e - ETA: 3:26 - loss: nan - accuracy: 0.0000e+ - ETA: 3:25 - loss: nan - accurac - ETA: 3:23 - loss: nan - accuracy - ETA: 3:20 - loss: nan - accuracy: 0.000 - ETA: 3:19 - loss: nan - accu - ETA: 3:17 - loss: nan - accuracy: 0.0 - ETA: 3:17 - loss: nan - accuracy: 0 - ETA: 3:15 - loss: nan - accuracy: 0.0000 - ETA: 3:14 - loss: nan - accuracy: 0.0000e+ - ETA: 3:14 - loss: nan - accuracy: 0.00 - ETA: 3:13 - loss: nan - accuracy: 0.0000e - ETA: 3:12 - loss: nan - accuracy: - ETA: 3:10 - loss: nan - accuracy: 0.0000e+ - ETA: 3:10 - loss: nan - accuracy: 0 - E - ETA: 3:02 - loss: nan - accurac - ETA: 2:59 - loss: nan - accuracy: 0.0000e+0 - ETA: 2:59 - loss: nan - accuracy: 0.0000e+0 - ETA: 2:59 - loss: nan - accuracy: 0.0000e - ETA: 2:58 - loss: nan - accuracy: 0.0000e+0 - ETA: 2:58 - loss: nan - accuracy: 0.0000 - ETA: 2:58 - loss: nan - accuracy: 0.0000e+0 - ETA: 2:58 - loss: nan - acc - ETA: 2:55 - loss: nan - ac - ETA: 2:53 - loss: nan - accuracy: 0.0 - ETA: 2:52 - lo - ETA: 2:47 - loss: nan - accuracy:  - ETA: 2:45 - loss: nan - ac - ETA: 2:42 - loss: nan - accuracy: 0 - ETA: 2:41 - loss: nan - accuracy - ETA: 2:39 - loss: nan - accuracy: 0.0000e+ - ETA: 2:39 - loss: nan - accuracy: 0.0000e+ - ETA: 2:38 - loss: nan - accuracy: - ETA: 2:37 - loss: nan - accuracy:  - ETA: 2:35 - loss: nan - accuracy: 0.0000e - ETA: 2:35 - loss: nan - accuracy: 0 - ETA: 2:33 - loss: nan -  - ETA: 2:31 - loss: nan - accuracy: 0 - ETA: 2:30 - loss: nan - accuracy: 0.0000e+0 - ETA: 2:29 - loss: nan - accuracy: 0.0000e+0 - ETA: 2:29 - loss: nan - accuracy: 0.0000e+ - ETA: 2:29 - loss: nan - ac - ETA: 2:26 - loss: nan - accuracy - ETA: 2:24 - loss: nan - accuracy: 0. - ETA: 2:23 - loss: nan - ETA: 2:20 - loss: nan - accuracy: 0.0000e+0 - ETA: 2:19 - loss: nan - acc - ETA: 2:17 - loss: nan - ac - ETA: 2:14 - loss: nan - accuracy - ETA: 2:13 - loss: nan - accuracy: 0.0 - ETA: 2:12 - loss: nan - accuracy: 0. - ETA: 2:04 - loss: nan - accuracy: 0.0000e+0 - ETA: 2: - ETA: 1:59 - loss: nan - accuracy: 0. - ETA: - ETA: 1:46 - loss: nan - acc  - ETA: 1:37 - loss: nan - accuracy - ETA: 1:35 - loss: nan - accuracy: 0.0000e+0 - ETA: 1:35 - loss: nan - acc - ETA: 1:33 - loss: nan -  - ETA: 1:31 - loss: nan - accuracy: 0.0000e - ETA: 1:30 - loss: nan - accuracy: 0.0000e - ETA: 1:30 - loss: nan - accuracy: 0.0000 - ETA: 1:29 - loss: nan - accuracy: 0 - ETA: 1:28 - loss: nan - accuracy: 0.0000e - ETA: 1:28 - loss: nan - accuracy: 0.0000e+0 - ETA: 1:28 - loss: nan - accuracy: 0.0000e+ - ETA: 1:27 - loss: nan - accuracy: 0.0000e+0 - ETA: 1:27 - loss: nan - accuracy: 0.0000e+ - ETA: 1:27 - loss: nan - accuracy: 0.0000e+0 - ETA: 1:27 - loss: nan - accuracy: 0.0000e+0 - ETA: 1:27 - loss: nan - accuracy: 0.0000e+0 - ETA: 1:27 - loss: nan - accuracy: 0.0000 - ETA: 1:26 - loss: nan - accuracy: 0.0000e - ETA: 1:26 - loss: nan - accuracy: 0.0000e+0 - ETA: 1:26 - loss: nan - accu - ETA: 1:24 - loss: nan  - ETA: 1:21 - loss: nan - accuracy: 0.0000e - ETA: 1:20 - loss: nan - acc - ETA: 1:18 - loss: nan - accuracy: 0.0000 - ETA: 1:18 - loss: nan - accuracy: 0.0000 - ETA: 1:17 - loss: nan - accuracy: 0.0000e+0 - ETA: 1:17 - loss: nan - accuracy: 0.0000e+0 - ETA: 1:17 - loss: nan - accuracy: 0.0000e - ETA: 1:17 - loss: nan - accuracy: 0.0000e+ - ETA: 1:17 - loss: nan - accuracy: 0.0 - ETA: 1:16 - loss: nan - accuracy: 0.0000 - ETA: 1:15 - loss: nan - accura - ETA: 1:13 - loss: nan - accuracy: 0.000 - ETA: 1:13 - loss: nan - accura - ETA: 1:11 - loss: nan - accuracy: 0. - ETA: 1:10 - loss: nan - accuracy: 0.0000e - ETA: 1:10 - loss: nan - accuracy: 0. - ETA: 1:09 - loss: nan - accuracy: 0.0000 - ETA: 1:08 - loss: nan - accuracy: 0.00 - ETA: 1:07 - loss: nan - accuracy: 0.0000e+0 - ETA: 1:07 - loss: nan - accuracy:  - ETA: 1:06 - loss: nan - accuracy: 0.0000e+ - ETA: 1:06 - loss: nan - accuracy: 0.0000e+ - ETA: 1:06 - loss: nan - accuracy: 0 - ETA: 1:05 - loss: nan "
     ]
    }
   ],
   "source": [
    "train_x, train_y, test_x, test_y, scaler =load_data(ddprice, sequence_length=10, split=0.7)\n",
    "# train_x 共 230*0.8=184 筆, test_x 共 230*0.2=46 筆\n",
    "#print(train_x.shape,train_y.shape) # (184,10,1) (184,1)\n",
    "#print(test_x.shape,test_y.shape)   # (46,10,1)  (46,1)\n",
    "predict_y, test_y = train_model(train_x, train_y, test_x, test_y)\n",
    "predict_y = scaler.inverse_transform([[i] for i in predict_y]) # 還原\n",
    "test_y = scaler.inverse_transform(test_y)  # 還原\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(predict_y, 'b:') #預測\n",
    "plt.plot(test_y, 'r-')    #收盤價\n",
    "plt.legend(['預測', '收盤價'])\n",
    "plt.show()\n",
    "\n",
    "# 建立 DataFrame，加入 predict_y、test_y，準備以 plotly 繪圖\n",
    "dd2=pd.DataFrame({\"predict\":list(predict_y),\"label\":list(test_y)})\n",
    "#轉換為 numpy 陣列，並轉為 float\n",
    "dd2[\"predict\"] = np.array(dd2[\"predict\"]).astype('float64')\n",
    "dd2[\"label\"] = np.array(dd2[\"label\"]).astype('float64')\n",
    "\n",
    "data = [\n",
    "    Scatter(y=dd2[\"predict\"],name='預測'),\n",
    "    Scatter(y=dd2[\"label\"],name='收盤價')\n",
    "] \n",
    "\n",
    "plot({\"data\": data, \"layout\": Layout(title='2018年個股預測圖')},auto_open=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
